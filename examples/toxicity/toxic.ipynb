{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/representation-engineering/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, pipeline, AutoModelForCausalLM\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from itertools import islice\n",
    "\n",
    "from repe import repe_pipeline_registry\n",
    "repe_pipeline_registry()\n",
    "\n",
    "from utils import toxicgen_concept_dataset\n",
    "import os\n",
    "from dotenv import load_dotenv, dotenv_values \n",
    "load_dotenv() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create concept dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_tag =  \"[INST]\"\n",
    "assistant_tag =  \"[/INST]\"\n",
    "\n",
    "dataset = toxicgen_concept_dataset(user_tag=user_tag, assistant_tag=assistant_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load llama model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:07<00:00,  2.42s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_name_or_path = \"meta-llama/Llama-2-13b-chat-hf\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name_or_path, torch_dtype=torch.bfloat16, device_map=\"auto\", token=os.getenv(\"access_token\")).eval()\n",
    "use_fast_tokenizer = \"LlamaForCausalLM\" not in model.config.architectures\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, use_fast=use_fast_tokenizer, padding_side=\"left\", legacy=False, token=os.getenv(\"access_token\"))\n",
    "tokenizer.pad_token_id = 0 if tokenizer.pad_token_id is None else tokenizer.pad_token_id\n",
    "tokenizer.bos_token_id = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate reading pipeline. \n",
    "- This pipeline is responsible for creating LAt vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "rep_token = -1\n",
    "n_components = 1\n",
    "hidden_layers = list(range(-1, -model.config.num_hidden_layers, -1))\n",
    "n_difference = 1\n",
    "direction_method = 'pca'\n",
    "rep_reading_pipeline =  pipeline(\"rep-reading\", model=model, tokenizer=tokenizer)\n",
    "direction_finder_kwargs= {\"n_components\": n_components}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use reading pipeline to get the toxicity representation vector\n",
    "- This will train a PCA model for each layer \n",
    "- The PCA model will capture the variance of difference between hidden representations for toxic statements and non-toxic statements\n",
    "- In the end it will compute the sign for each layer i.e. \n",
    "    - Compute projection scalar component of projection of hidden representation for toxic and non toxic statement on reading vector \n",
    "    - Compute the mean and take the sign\n",
    "- This representation will be used to calculate accuracy for validation and test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size=2\n",
    "max_length = 20,\n",
    "\n",
    "rep_reader = rep_reading_pipeline.get_directions(\n",
    "        dataset['train']['data'], \n",
    "        rep_token=rep_token, \n",
    "        hidden_layers=hidden_layers, \n",
    "        n_difference=n_difference, \n",
    "        train_labels=dataset['train']['labels'], \n",
    "        direction_method=direction_method,\n",
    "        direction_finder_kwargs=direction_finder_kwargs,\n",
    "        batch_size=batch_size,\n",
    "        max_length=max_length,\n",
    "        padding=\"longest\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the results on validation and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = {'val': [], 'test': []}\n",
    "datasets = [('val', dataset['val']), ('test', dataset['test'])]\n",
    "\n",
    "\n",
    "for t, eval_data in datasets:\n",
    "    if not eval_data: continue\n",
    "\n",
    "    H_tests = rep_reading_pipeline(\n",
    "        eval_data['data'],\n",
    "        rep_token=rep_token,\n",
    "        hidden_layers=hidden_layers,\n",
    "        rep_reader=rep_reader,\n",
    "        batch_size=batch_size,\n",
    "        max_length=max_length,\n",
    "        padding=\"longest\"\n",
    "    )\n",
    "\n",
    "    labels = eval_data['labels']\n",
    "    for layer in hidden_layers:\n",
    "        H_test = [H[layer] for H in H_tests]\n",
    "\n",
    "        # unflatten into chunks of choices\n",
    "        unflattened_H_tests = [list(islice(H_test, sum(len(c) for c in labels[:i]), sum(len(c) for c in labels[:i+1]))) for i in range(len(labels))]\n",
    "\n",
    "        sign = rep_reader.direction_signs[layer]\n",
    "        eval_func = np.argmin if sign == -1 else np.argmax\n",
    "        cors = np.mean([labels[i].index(1) == eval_func(H) for i, H in enumerate(unflattened_H_tests)])\n",
    "\n",
    "        results[t].append(cors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation acc at layer: -1; acc: 1.0\n",
      "Test Acc for chosen layer: -1 - 1.0\n"
     ]
    }
   ],
   "source": [
    "if dataset['val']:\n",
    "    best_layer_idx = results['val'].index(max(results['val']))\n",
    "    best_layer = hidden_layers[best_layer_idx]\n",
    "    print(f\"Best validation acc at layer: {best_layer}; acc: {max(results['val'])}\")\n",
    "    print(f\"Test Acc for chosen layer: {best_layer} - {results['test'][best_layer_idx]}\")\n",
    "else:\n",
    "    best_layer_idx = results['test'].index(max(results['test']))\n",
    "    best_layer = hidden_layers[best_layer_idx]\n",
    "    print(f\"Best test acc at layer: {best_layer}; acc: {max(results['test'])}\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "torch_repe_engg",
   "name": "workbench-notebooks.m129",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m129"
  },
  "kernelspec": {
   "display_name": "torch_repe_engg (Local)",
   "language": "python",
   "name": "torch_repe_engg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
